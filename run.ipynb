{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install library\n",
    "!: Digunakan untuk menginstall library python secara massal\n",
    "\n",
    "Split-folders: Library untuk membagi dataset menjadi train set dan validation set dengan mudah\n",
    "\n",
    "Pathlib: Library untuk memanipulasi path dan file system pada Python\n",
    "\n",
    "Matplotlib: Library untuk membuat plot visualisasi data\n",
    "\n",
    "Tensorflow: Library open-source untuk mengembangkan model machine learning\n",
    "\n",
    "Pillow: Library untuk manipulasi gambar, seperti mengubah ukuran, memotong, dan memutar gambar\n",
    "\n",
    "Numpy: Library Python yang digunakan untuk mengelola array dan matriks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install split-folders pathlib matplotlib tensorflow pillow numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembagian dataset\n",
    "Ratio yang digunakan adalah 80:20, 80% dataset dan 20% validation set\n",
    "\n",
    "Seed digunakan untuk merandomize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8931,
     "status": "ok",
     "timestamp": 1679389956472,
     "user": {
      "displayName": "Nabil Colabs",
      "userId": "09656267091655518948"
     },
     "user_tz": -420
    },
    "id": "YVC2Ze1oT36D",
    "outputId": "06ee79d0-45c4-4f7f-cedc-5df2de65680d"
   },
   "outputs": [],
   "source": [
    "import splitfolders as sf\n",
    "\n",
    "sf.ratio(r\"C:\\Users\\arfan\\train\\Model\\dataset\", output=r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\",\n",
    "    seed=42, ratio=(.8, .2), group_prefix=None, move=False) # default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menentukan direktori train set dan validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzjMHRFUq8r6"
   },
   "outputs": [],
   "source": [
    "train_dir = r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\\train\"\n",
    "validation_dir = r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\\val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memuat foto\n",
    "Menampilkan foto landmark dari dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "# Menentukan direktori dataset dan kelasnya\n",
    "train_dir = r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\\train\"\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "\n",
    "# Menampilkan beberapa gambar secara acak dari setiap kelas\n",
    "fig, ax = plt.subplots(nrows=len(class_names), ncols=4, figsize=(10, 20))\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    image_names = os.listdir(class_dir)\n",
    "    for j in range(4):\n",
    "        image_name = random.choice(image_names)\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "        image = load_img(image_path, target_size=(224, 224))\n",
    "        ax[i][j].imshow(image)\n",
    "        ax[i][j].set_title(class_name)\n",
    "        ax[i][j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memuat data dan memproses data\n",
    "ImageDataGenerator untuk melakukan augmentasi data pada dataset training.\n",
    "\n",
    "Flow_from_directory untuk membaca dataset train dan validation dari direktori yang telah ditentukan sebelumnya\n",
    "\n",
    "Sparse pada class_mode, output dari generator akan berupa array 1 dimensi yang berisi nilai integer yang merepresentasikan kelas dari setiap sampel pada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4567,
     "status": "ok",
     "timestamp": 1679813193444,
     "user": {
      "displayName": "Nabil Colabs",
      "userId": "09656267091655518948"
     },
     "user_tz": -420
    },
    "id": "lYZER78-q1mc",
    "outputId": "a6328c5b-9b05-45ef-951e-71ebe431b6ed"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "# Melakukan image augmentation pada dataset untuk menambah variasi data\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                    horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "# Melakukan data generator untuk membaca dataset training di setiap label\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'sparse', \n",
    "                                                    target_size = (224, 224))     \n",
    "\n",
    "# Melakukan data generator untuk membaca dataset testing di setiap label\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 32,\n",
    "                                                          class_mode  = 'sparse', \n",
    "                                                          target_size = (224, 224))\n",
    "\n",
    "# Menampilkan beberapa gambar yang telah di-augmentasi\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(10, 10))\n",
    "for i in range(0, 3):\n",
    "    for j in range(0, 4):\n",
    "        image, label = next(train_generator)\n",
    "        ax[i][j].imshow(image[0])\n",
    "        ax[i][j].set_title(f\"Label: {int(label[0])}\")\n",
    "        ax[i][j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling\n",
    "Digunakan untuk melakukan mapping dari label integer ke nama kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merepresentasikan label integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjLgGYRwWLzB"
   },
   "source": [
    "# Arsitektur model\n",
    "Mengimport library yang dibutuhkan untuk modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlYP7zB1XIOc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penjelasan \n",
    "Model Sequential adalah model neural network yang terdiri dari sekumpulan layer yang saling tersambung secara berurutan.\n",
    "\n",
    "Conv2D(): fungsi ini digunakan untuk menambahkan layer konvolusi pada model. Layer konvolusi digunakan untuk memproses citra dengan melakukan operasi konvolusi pada citra input.\n",
    "\n",
    "MaxPooling2D(): fungsi ini digunakan untuk menambahkan layer pooling pada model. Layer pooling digunakan untuk mengekstraksi fitur-fitur penting dari citra input dengan melakukan operasi pooling pada citra.\n",
    "\n",
    "Flatten(): fungsi ini digunakan untuk menambahkan layer flatten pada model. Layer flatten digunakan untuk meratakan output dari layer sebelumnya menjadi sebuah vektor satu dimensi.\n",
    "\n",
    "Dense(): fungsi ini digunakan untuk menambahkan layer fully connected pada model. Layer fully connected digunakan untuk menghubungkan setiap neuron dari layer sebelumnya dengan setiap neuron pada layer selanjutnya.\n",
    "\n",
    "Dropout(): fungsi ini digunakan untuk menambahkan layer dropout pada model. Layer dropout digunakan untuk mengurangi overfitting pada model dengan secara acak menonaktifkan beberapa neuron pada layer sebelumnya.\n",
    "\n",
    "Activation: parameter ini digunakan untuk menentukan fungsi aktivasi pada setiap layer. Fungsi aktivasi digunakan untuk menambahkan sifat non-linear pada model sehingga model dapat mempelajari fitur-fitur yang kompleks.\n",
    "\n",
    "Input_shape: parameter ini digunakan untuk menentukan ukuran input pada layer pertama. Ukuran input pada layer pertama harus sama dengan ukuran citra input.\n",
    "\n",
    "Pool_size: parameter ini digunakan untuk menentukan ukuran window pada layer pooling. Ukuran window pada layer pooling digunakan untuk menentukan berapa banyak fitur yang akan dikeluarkan dari citra input pada setiap operasi pooling.\n",
    "\n",
    "Model.add(Dense(5, activation='softmax')): Menambahkan layer Dense (fully connected) dengan 5 neuron yang merepresentasikan 5 kelas output yang diinginkan, dan menggunakan fungsi aktivasi softmax untuk mendapatkan nilai probabilitas untuk setiap kelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi model\n",
    "model = Sequential()\n",
    "\n",
    "# Tambahkan layer pertama Conv2D dengan 32 filter dan ukuran kernel 3x3\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "\n",
    "# Tambahkan layer MaxPooling2D dengan ukuran pool 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Tambahkan layer kedua Conv2D dengan 64 filter dan ukuran kernel 3x3\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Tambahkan layer MaxPooling2D dengan ukuran pool 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Tambahkan layer ketiga Conv2D dengan 128 filter dan ukuran kernel 3x3\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Tambahkan layer MaxPooling2D dengan ukuran pool 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Tambahkan layer keempat Conv2D dengan 256 filter dan ukuran kernel 3x3\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "\n",
    "# Tambahkan layer MaxPooling2D dengan ukuran pool 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Tambahkan layer Flatten untuk mengubah input menjadi 1 dimensi\n",
    "model.add(Flatten())\n",
    "\n",
    "# Tambahkan layer Dense dengan 256 unit dan aktivasi relu\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Tambahkan layer Dropout untuk mencegah overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Tambahkan layer Dense terakhir dengan 5 unit dan aktivasi softmax untuk mendapatkan nilai probabilitas dari 5 kelas\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hasil model pembelajaran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model\n",
    "\n",
    "Optimizer adam digunakan untuk optimasi yang akan menyesuaikan bobot dalam jaringan saraf tiruan\n",
    "\n",
    "Fungsi loss yang digunakan untuk mengevaluasi seberapa baik model bekerja pada setiap iterasi. Karena output dari model merupakan label kelas yang berupa integer\n",
    "\n",
    "Metrics accuracy digunakan untuk mengevaluasi kinerja model selama pelatihan dan pengujian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melatih model sebanyak 100 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 1013425,
     "status": "error",
     "timestamp": 1679814603821,
     "user": {
      "displayName": "Nabil Colabs",
      "userId": "09656267091655518948"
     },
     "user_tz": -420
    },
    "id": "kD_X-sIMrytW",
    "outputId": "f3ca1531-4ca8-450a-e67b-cf4627f3d4de"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, validation_data=validation_generator, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZ-Efy2KWOO_"
   },
   "source": [
    "# Evaluasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafik pertama menampilkan akurasi pelatihan dan validasi terhadap jumlah epoch yang dilakukan\n",
    "\n",
    "Grafik kedua menampilkan loss pelatihan dan validasi terhadap jumlah epoch yang dilakukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "executionInfo": {
     "elapsed": 1024,
     "status": "ok",
     "timestamp": 1679389697199,
     "user": {
      "displayName": "Nabil Colabs",
      "userId": "09656267091655518948"
     },
     "user_tz": -420
    },
    "id": "X13tiPGROUkH",
    "outputId": "38da8024-1fdf-4580-c8ca-f9cf59aa5e79"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#history akurasi\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "#history loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#subplot akurasi\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "#subplot loss\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan model\n",
    "Hasil model pembelajaran disimpan dengan extension h5, model.h5 akan digunakan untuk pembuatan web aplikasi menggunakan streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAEGnm3xKUQ4"
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87jzJneSWQrv"
   },
   "source": [
    "# Pengujian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gambar_folder = pl.Path(\"19_e.jpg\")\n",
    "nama_class = ['Candi Borobudur', 'Gedung Sate', 'Istana Maimun', 'Jembatan Ampera', 'Monumen Nasional']\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Load gambar dan konversi ke array\n",
    "gambar = tf.keras.utils.load_img(gambar_folder, target_size=(224, 224))\n",
    "gambar_toarray = tf.keras.utils.img_to_array(gambar)\n",
    "gambar_toarray = tf.expand_dims(gambar_toarray, 0) \n",
    "\n",
    "# Lakukan prediksi menggunakan model\n",
    "prediksi = model.predict(gambar_toarray)\n",
    "kelas_prediksi = nama_class[np.argmax(prediksi)]\n",
    "\n",
    "# Tampilkan gambar dan hasil prediksi\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(gambar)\n",
    "ax.set_title(\"Diklasifikasikan Sebagai Landmark: {}\".format(kelas_prediksi))\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian tanpa jumlah total tanpa nama file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definisikan path ke folder dataset\n",
    "path = pl.Path(r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\\val\")\n",
    "\n",
    "# Definisikan nama class\n",
    "nama_class = ['Candi Borobudur', 'Gedung Sate', 'Istana Maimun', 'Jembatan Ampera', 'Monumen Nasional']\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Definisikan ImageDataGenerator untuk melakukan augmentasi gambar pada data testing\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data testing dari folder menggunakan ImageDataGenerator\n",
    "test_data = test_datagen.flow_from_directory(directory=path,\n",
    "                                             target_size=(224, 224),\n",
    "                                             classes=nama_class,\n",
    "                                             class_mode='sparse',\n",
    "                                             shuffle=False)\n",
    "\n",
    "# Lakukan prediksi menggunakan model pada data testing\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Ambil indeks kelas dengan nilai probabilitas tertinggi dari setiap prediksi\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Tampilkan hasil prediksi\n",
    "for i, img, in enumerate(test_data.filenames):\n",
    "    # Load gambar\n",
    "    img_path = path / img\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    # Tampilkan gambar dan hasil prediksi\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(\"Diklasifikasikan Sebagai Landmark: {}\".format(nama_class[predicted_classes[i]]))\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian tanpa gambar ( old code )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "\n",
    "gambar_folder = pl.Path(r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\\val\")\n",
    "nama_class = ['Candi Borobudur', 'Gedung Sate', 'Jembatan Ampera', 'Istana Maimun', 'Monumen Nasional']\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "for class_name in nama_class:\n",
    "    class_folder = gambar_folder / class_name\n",
    "    for image_path in class_folder.glob('*.jpg'):\n",
    "        gambar = tf.keras.utils.load_img(image_path, target_size=(224, 224))\n",
    "        gambar_toarray = tf.keras.utils.img_to_array(gambar)\n",
    "        gambar_toarray = tf.expand_dims(gambar_toarray, 0) \n",
    "        prediksi = model.predict(gambar_toarray)\n",
    "        presentase = tf.nn.softmax(prediksi[0])\n",
    "        print(\"Gambar {} diklasifikasikan sebagai Landmark: {}\"\n",
    "              .format(image_path.name, nama_class[np.argmax(presentase)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian menampilkan persentase dengan nama landmark bukan nama file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definisikan path ke folder dataset\n",
    "path = pl.Path(r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\\val\")\n",
    "\n",
    "# Definisikan nama class\n",
    "nama_class = ['Candi Borobudur', 'Gedung Sate', 'Istana Maimun', 'Jembatan Ampera', 'Monumen Nasional']\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Definisikan ImageDataGenerator untuk melakukan augmentasi gambar pada data testing\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data testing dari folder menggunakan ImageDataGenerator\n",
    "test_data = test_datagen.flow_from_directory(directory=path,\n",
    "                                             target_size=(224, 224),\n",
    "                                             classes=nama_class,\n",
    "                                             class_mode='sparse',\n",
    "                                             shuffle=False)\n",
    "\n",
    "# Lakukan prediksi menggunakan model pada data testing\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Ambil indeks kelas dengan nilai probabilitas tertinggi dari setiap prediksi\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Tampilkan hasil prediksi\n",
    "for i, img, in enumerate(test_data.filenames):\n",
    "    # Load gambar\n",
    "    img_path = path / img\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    # Ambil probabilitas untuk setiap kelas\n",
    "    probabilities = predictions[i]\n",
    "    \n",
    "    # Tampilkan gambar dan hasil prediksi\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(\"Diklasifikasikan Sebagai Landmark: {}\".format(nama_class[predicted_classes[i]]))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Tambahkan probabilitas persen dan nama file gambar pada hasil output\n",
    "    for j, prob in enumerate(probabilities):\n",
    "        class_name = nama_class[j]\n",
    "        percentage = prob * 100\n",
    "        text = \"{}: {:.2f}%\".format(class_name, percentage)\n",
    "        plt.text(10, 20 + j * 20, text, color='white', backgroundcolor='black')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian dengan total jumlah dan probabilitas tetapi tidak ada nama file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definisikan path ke folder dataset\n",
    "path = pl.Path(r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\\val\")\n",
    "\n",
    "# Definisikan nama class\n",
    "nama_class = ['Candi Borobudur', 'Gedung Sate', 'Istana Maimun', 'Jembatan Ampera', 'Monumen Nasional']\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Definisikan ImageDataGenerator untuk melakukan augmentasi gambar pada data testing\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data testing dari folder menggunakan ImageDataGenerator\n",
    "test_data = test_datagen.flow_from_directory(directory=path,\n",
    "                                             target_size=(224, 224),\n",
    "                                             classes=nama_class,\n",
    "                                             class_mode='sparse',\n",
    "                                             shuffle=False)\n",
    "\n",
    "# Lakukan prediksi menggunakan model pada data testing\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Ambil indeks kelas dengan nilai probabilitas tertinggi dari setiap prediksi\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Inisialisasi variabel untuk menghitung prediksi yang benar dan salah\n",
    "correct_predictions = 0\n",
    "incorrect_predictions = 0\n",
    "\n",
    "# Tampilkan hasil prediksi\n",
    "for i, img, in enumerate(test_data.filenames):\n",
    "    # Load gambar\n",
    "    img_path = path / img\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    # Ambil probabilitas untuk setiap kelas\n",
    "    probabilities = predictions[i]\n",
    "    \n",
    "    # Tampilkan gambar dan hasil prediksi\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Periksa apakah prediksi benar atau salah\n",
    "    if predicted_classes[i] == test_data.labels[i]:\n",
    "        ax.set_title(\"Prediksi Benar: {}\".format(nama_class[predicted_classes[i]]))\n",
    "        correct_predictions += 1\n",
    "    else:\n",
    "        ax.set_title(\"Prediksi Salah: {}\".format(nama_class[predicted_classes[i]]))\n",
    "        incorrect_predictions += 1\n",
    "    \n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Tambahkan probabilitas persen dan nama file gambar pada hasil output\n",
    "    for j, prob in enumerate(probabilities):\n",
    "        class_name = nama_class[j]\n",
    "        percentage = prob * 100\n",
    "        text = \"{}: {:.2f}%\".format(class_name, percentage)\n",
    "        plt.text(10, 20 + j * 20, text, color='white', backgroundcolor='black')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Tampilkan jumlah prediksi yang benar dan salah\n",
    "print(\"Jumlah Prediksi Benar: \", correct_predictions)\n",
    "print(\"Jumlah Prediksi Salah: \", incorrect_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian dengan nama file dan nama landmark dan total jumlah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definisikan path ke folder dataset\n",
    "path = pl.Path(r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\\val\")\n",
    "\n",
    "# Definisikan nama class\n",
    "nama_class = ['Candi Borobudur', 'Gedung Sate', 'Istana Maimun', 'Jembatan Ampera', 'Monumen Nasional']\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Definisikan ImageDataGenerator untuk melakukan augmentasi gambar pada data testing\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data testing dari folder menggunakan ImageDataGenerator\n",
    "test_data = test_datagen.flow_from_directory(directory=path,\n",
    "                                             target_size=(224, 224),\n",
    "                                             classes=nama_class,\n",
    "                                             class_mode='sparse',\n",
    "                                             shuffle=False)\n",
    "\n",
    "# Lakukan prediksi menggunakan model pada data testing\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Ambil indeks kelas dengan nilai probabilitas tertinggi dari setiap prediksi\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Inisialisasi variabel untuk menghitung prediksi yang benar dan salah\n",
    "correct_predictions = 0\n",
    "incorrect_predictions = 0\n",
    "\n",
    "# Tampilkan hasil prediksi\n",
    "for i, img, in enumerate(test_data.filenames):\n",
    "    # Load gambar\n",
    "    img_path = path / img\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    # Ambil probabilitas untuk setiap kelas\n",
    "    probabilities = predictions[i]\n",
    "    \n",
    "    # Tampilkan gambar dan hasil prediksi\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Periksa apakah prediksi benar atau salah\n",
    "    if predicted_classes[i] == test_data.labels[i]:\n",
    "        ax.set_title(\"Prediksi Benar: {} - {}\".format(nama_class[predicted_classes[i]], img_path.name))\n",
    "        correct_predictions += 1\n",
    "    else:\n",
    "        ax.set_title(\"Prediksi Salah: {} - {}\".format(nama_class[predicted_classes[i]], img_path.name))\n",
    "        incorrect_predictions += 1\n",
    "    \n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Tambahkan probabilitas persen dan nama file gambar pada hasil output\n",
    "    for j, prob in enumerate(probabilities):\n",
    "        class_name = nama_class[j]\n",
    "        percentage = prob * 100\n",
    "        text = \"{}: {:.2f}%\".format(class_name, percentage)\n",
    "        plt.text(10, 20 + j * 20, text, color='white', backgroundcolor='black')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Tampilkan jumlah prediksi yang benar dan salah\n",
    "print(\"Jumlah Prediksi Benar: \", correct_predictions)\n",
    "print(\"Jumlah Prediksi Salah: \", incorrect_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian dengan nama file total file benar salah dan nama file yang salah ada nama landmark juga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definisikan path ke folder dataset\n",
    "path = pl.Path(r\"C:\\Users\\arfan\\train\\Model\\dataset_splitfolder\\val\")\n",
    "\n",
    "# Definisikan nama class\n",
    "nama_class = ['Candi Borobudur', 'Gedung Sate', 'Istana Maimun', 'Jembatan Ampera', 'Monumen Nasional']\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Definisikan ImageDataGenerator untuk melakukan augmentasi gambar pada data testing\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data testing dari folder menggunakan ImageDataGenerator\n",
    "test_data = test_datagen.flow_from_directory(directory=path,\n",
    "                                             target_size=(224, 224),\n",
    "                                             classes=nama_class,\n",
    "                                             class_mode='sparse',\n",
    "                                             shuffle=False)\n",
    "\n",
    "# Lakukan prediksi menggunakan model pada data testing\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Ambil indeks kelas dengan nilai probabilitas tertinggi dari setiap prediksi\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Inisialisasi variabel untuk menghitung prediksi yang benar dan salah\n",
    "correct_predictions = 0\n",
    "incorrect_predictions = 0\n",
    "incorrect_files = []\n",
    "\n",
    "# Tampilkan hasil prediksi\n",
    "for i, img, in enumerate(test_data.filenames):\n",
    "    # Load gambar\n",
    "    img_path = path / img\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    # Ambil probabilitas untuk setiap kelas\n",
    "    probabilities = predictions[i]\n",
    "    \n",
    "    # Tampilkan gambar dan hasil prediksi\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Periksa apakah prediksi benar atau salah\n",
    "    if predicted_classes[i] == test_data.labels[i]:\n",
    "        ax.set_title(\"Prediksi Benar: {} - {}\".format(nama_class[predicted_classes[i]], img_path.name))\n",
    "        correct_predictions += 1\n",
    "    else:\n",
    "        ax.set_title(\"Prediksi Salah: {} - {}\".format(nama_class[predicted_classes[i]], img_path.name))\n",
    "        incorrect_predictions += 1\n",
    "        incorrect_files.append(img_path.name)\n",
    "    \n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Tambahkan probabilitas persen dan nama file gambar pada hasil output\n",
    "    for j, prob in enumerate(probabilities):\n",
    "        class_name = nama_class[j]\n",
    "        percentage = prob * 100\n",
    "        text = \"{}: {:.2f}%\".format(class_name, percentage)\n",
    "        plt.text(10, 20 + j * 20, text, color='white', backgroundcolor='black')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Tampilkan jumlah prediksi yang benar dan salah\n",
    "print(\"Jumlah Prediksi Benar: \", correct_predictions)\n",
    "print(\"Jumlah Prediksi Salah: \", incorrect_predictions)\n",
    "print(\"Nama File yang Salah:\", incorrect_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dPjP2UrjV3KJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
